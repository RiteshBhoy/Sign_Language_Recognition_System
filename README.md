# Sign Language Recognition using Machine Learning

## Overview

This project focuses on recognizing hand gestures in sign language using Machine Learning techniques. It utilizes Python and OpenCV for image processing and machine learning algorithms for recognizing and classifying hand signs into corresponding text labels.

The goal is to build a system capable of interpreting sign language gestures, which can be helpful for enhancing communication for people with hearing impairments.

---

## Features

- **Real-time Gesture Recognition**: Recognizes hand gestures and translates them into text using a webcam or images.
- **Machine Learning Model**: Utilizes preprocessed datasets to train a classifier that can detect different sign language gestures.
- **Customizable**: You can easily add more gestures by augmenting the dataset and retraining the model.
- **Accuracy**: The system achieves a reasonable accuracy level based on the dataset and model architecture used.

---

## Technologies Used

- **Python**: The core programming language used for this project.
- **OpenCV**: For image processing tasks like capturing and preprocessing the input images.
- **TensorFlow / Keras**: For building and training machine learning models, specifically Convolutional Neural Networks (CNNs) for gesture recognition.
## To run the Application 
python Dashboard.py
